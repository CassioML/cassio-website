{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730896c3",
   "metadata": {},
   "source": [
    "# TODOS\n",
    "\n",
    "colab people:\n",
    "\n",
    "- warn about switching to gpu runtime _at the beginning_\n",
    "- _remove_ the need for an LLM in the colabification preamble\n",
    "\n",
    "todos:\n",
    "\n",
    "- test on a fresh venv with versions pinned\n",
    "- test locally and on tpu/gpu/cpy colabs!\n",
    "- test with actual audio playing\n",
    "- single/double quotes uniform\n",
    "- better handling of bitrate (self-detect. Both in loading and showing \"Audio\"), and mp3?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0e82f-95fa-4efa-84e3-9873d4dcdaf1",
   "metadata": {
    "id": "8ee0e82f-95fa-4efa-84e3-9873d4dcdaf1"
   },
   "source": [
    "# Sound Similarity Search with Vector Database\n",
    "\n",
    "Use CassIO and Astra DB / Apache CassandraÂ® for similarity searches between **sound samples**, powered by sound embeddings and Vector Search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdb8284",
   "metadata": {},
   "source": [
    "_**NOTE:** this uses Cassandra's \"Vector Similarity Search\" capability.\n",
    "Make sure you are connecting to a vector-enabled database for this demo._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bc1d2f-7039-4d2a-950c-ff3686013c55",
   "metadata": {
    "id": "58bc1d2f-7039-4d2a-950c-ff3686013c55"
   },
   "source": [
    "In this notebook you will:\n",
    "\n",
    "1. Download a library of sound samples from HuggingFace Datasets.\n",
    "2. Calculate sound embedding vectors for them with PANNs Inference.\n",
    "3. Store the embedding vectors on a table in your Cassandra / Astra DB instance, using the CassIO library for ease of operation.\n",
    "4. Run one or more searches for sounds similar to a provided sample.\n",
    "5. Start a simple web-app that exposes a **sound search** feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49d8157",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c18332",
   "metadata": {},
   "source": [
    "The CassIO object needed for this demo is the `VectorTable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f9dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassio.vector import VectorTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48",
   "metadata": {
    "id": "25d08ec4-0e7b-4819-933f-43ed5ff95e48"
   },
   "source": [
    "Other packages are needed for various tasks in this demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54137e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import Audio\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# processing of sound samples:\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "# HuggingFace dataset loading:\n",
    "from datasets import load_dataset\n",
    "# Sound embedding calculation:\n",
    "from panns_inference import AudioTagging\n",
    "# To spawn simple data-oriented UIs from the notebook\n",
    "import gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01da99af-da9b-4f38-b841-d802ff23bf2f",
   "metadata": {
    "id": "01da99af-da9b-4f38-b841-d802ff23bf2f"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import files\n",
    "    IS_COLAB = True\n",
    "except ModuleNotFoundError:\n",
    "    IS_COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d",
   "metadata": {
    "id": "b7a93b64-e9e9-41d1-95c9-dc9194a5ec8d"
   },
   "source": [
    "### Connect to your DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb2e30",
   "metadata": {},
   "source": [
    "A database connection is needed to access Cassandra. The following assumes\n",
    "that a _vector-search-capable Astra DB instance_ is available. Adjust as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13127a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cqlsession import getCQLSession, getCQLKeyspace\n",
    "cqlMode = 'astra_db' # 'astra_db'/'local'\n",
    "session = getCQLSession(mode=cqlMode)\n",
    "keyspace = getCQLKeyspace(mode=cqlMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CCOnMYJoxLJw",
   "metadata": {
    "id": "CCOnMYJoxLJw"
   },
   "source": [
    "\n",
    "## Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otdRjVbexV-V",
   "metadata": {
    "id": "otdRjVbexV-V"
   },
   "source": [
    "In this demo, you will use audio samples from the [ESC-50 dataset](https://github.com/karolpiczak/ESC-50), a labeled collection of 2000 environmental audio recordings, each with a duration of five seconds.\n",
    "\n",
    "The dataset can be loaded from the HuggingFace model hub as follows:\n",
    "\n",
    "_(Note that, unless already cached, the download operation may take a few minutes.)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7oWJORavxb5H",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336,
     "referenced_widgets": [
      "605332ecae664a6eb9929badc8c7827b",
      "78045cbdfcb14cae85e2e8724a4c8301",
      "a4f56ca0d4d34f02b509a2ae2969c05b",
      "446b1900cc6f4636ad50fa26cc4e98d3",
      "34abcc6a32444026a86ad8268078c95c",
      "23cb3fe481a34e828c1018e46a25f4c1",
      "5251435473a54205ae67da602838e648",
      "98f780065b3e480ba2b8eaa8a68c70bb",
      "0afe44ce894742a7b3b6c9691f2183dd",
      "ffe83400626e43e69fa152f5290f678c",
      "a952651d0ba44905baa6133cdc8ff4c6",
      "f3adb3fe859d43fb9d25d9438319bb98",
      "101ff9f649204bd39ca2495435658de5",
      "b368155cfc814ea0b5637d3c9598ad13",
      "5fe788b4c0984ab2b3d630104c75f5b3",
      "cec2fb0b38df4904ae09b650ca299112",
      "ca2360e63d914606a306cdc0fb3f1088",
      "1ef6bbae1f064b20859de273525f904c",
      "b21d77a2815e42d5bb96073a70ec647a",
      "9dbc7bebe45c4ba188d0bdbbfeb177d5",
      "2d3cac1f6b444b12907f9f8f4e4e723d",
      "202baa036c9446d589c60115161d49d0",
      "de7ce591f8d44988a03db2dc2dc38853",
      "955cc02a0bae4931a75b37751d873c54",
      "5f48cdae968f4bee8ff37d931727ef98",
      "795664c7e8c14ccb8b441636242bb91f",
      "282f5839dc164898a4d8a4484ac1022b",
      "873ace58e95f4d168362733d00501e9c",
      "0c603ec617e540ccbfe6811c34fec308",
      "9475297614624e028f5337aac190d9ec",
      "7ace14a3d8d34128adb7ce8463e55b97",
      "c00b517f55d547e1afe722e8105f9c12",
      "d5d8d84d94b040508a68229ec093118b",
      "1a78873204c94265a9ad02a265c0c557",
      "5d6e57d3918344ad99410a12a139cecd",
      "bcf3c45cf4994e8796bbe5f94fe23b7f",
      "d9a86d6349e14deeae3916eb0d1d94bb",
      "c7aa32ea6d2a4b6eb1af521eae8f24af",
      "5ebdab60580a4afcbf73b70c15d8b2af",
      "3603abbafa27471c9b2444bd3fae7261",
      "59753dff426f4beda609924c91cca268",
      "2ef1364c8ee045589835cdf7327e68cd",
      "b6ac5a2c55874d97a6b36fe8b1887f91",
      "c1bc7407260c4a388c452a9ae80d3edc",
      "d86b3ef7ee88413b9e2560c72be7c3c8",
      "4c7218fd8c48421cb44b59f6ea630b17",
      "6b3f865ff3964217b97fee8567287d21",
      "71e11505d09844d2b62ab3d7f981a257",
      "6bad17589fd84c3d9753f80d538b3dc3",
      "edda7cd670f34d3a93309132aef9f6aa",
      "0abbdc15884f4f47b4fccb1dfc8b98d0",
      "5872fe9cd54c49459fd54014dcf866c8",
      "4aaf2e5c07794fa19bf6a90c8a96bf4b",
      "219e186138c0457983c359826fa2c744",
      "3fd6251253ff43a89f1dc8df479c8039",
      "69201dbfbb1c4267bddf7aa85de082f0",
      "b4ad7a3be8d84a9eb3297c31d1ace08c",
      "cee25f8161204c6bae82ffcfebbe4a47",
      "0aed1f84a6cb4eb1bf26a806a1e7c7a4",
      "bfba6da068ab4c449e8299627af31197",
      "53413b361fa4432b977f7f7c7775a698",
      "827dedfeb76f47ea867edf309aaf90bb",
      "a97c7c6ca9fd45c59c7ece3a24335838",
      "504c8be25a40439ba648bf181a403e6e",
      "7aac70ce71ec4f97968166c5582507ce",
      "957e845c503541689bbbd071e1c7a1de",
      "dff7c6e15d7f4d47ad2a957ea12ab6d0",
      "719b600d4b464ff68b9e4563f8844c29",
      "5a4175f45e1345eaaac8f6f42ca4eb5b",
      "0b60c132af464a039a2b3d789b61b1ad",
      "5a5408a9a93f4dceb1feedf9404d5c0d",
      "2e8d32cec4914615abe9ec15811c8412",
      "e2b6fd395b2a4ac693728dd51e9e0241",
      "a295e48af5294be8b43003e8d9804300",
      "2e17c241a9a24623bef72b8e5aaeb6e7",
      "bf6e9846c3f249e0a8befb387741ddda",
      "f9d7030b71e24858a881140cd0b65026"
     ]
    },
    "id": "7oWJORavxb5H",
    "outputId": "9b93862e-306a-41f1-a7f5-cc942f1dc672"
   },
   "outputs": [],
   "source": [
    "audio_dataset = load_dataset(\"ashraq/esc50\", split=\"train\")\n",
    "\n",
    "# take a look...\n",
    "print(audio_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7HKVt8olAvkm",
   "metadata": {
    "id": "7HKVt8olAvkm"
   },
   "source": [
    "Each sample belongs to a \"category\". Take a look at the category for the first few items in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "FE1o9dCdxulj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FE1o9dCdxulj",
    "outputId": "cdd4ecce-001a-4b03-96e5-618a0f5be59d"
   },
   "outputs": [],
   "source": [
    "print(\"Categories:\")\n",
    "print(audio_dataset['category'][:5])\n",
    "print(\"\\nFilenames:\")\n",
    "print(audio_dataset['filename'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yaKxOuSTxjd0",
   "metadata": {
    "id": "yaKxOuSTxjd0"
   },
   "source": [
    "The actual audio signal is sampled at 44100 Hz and available as a NumPy array. Take a look at the first entries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aSYcIZaLxkbr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aSYcIZaLxkbr",
    "outputId": "29152d14-600d-47cc-ccf5-4b5faa1c51fa"
   },
   "outputs": [],
   "source": [
    "audios0 = audio_dataset[\"audio\"]\n",
    "audios0[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Y5SWFdnKyQbk",
   "metadata": {
    "id": "Y5SWFdnKyQbk"
   },
   "source": [
    "Convert the `array` members above into a NumPy object for ease of access later (when feeding the audio-embedding calculation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "q2QoVbv7ySoG",
   "metadata": {
    "id": "q2QoVbv7ySoG"
   },
   "outputs": [],
   "source": [
    "audios = np.array([a[\"array\"] for a in audios0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97gYTdw3xt17",
   "metadata": {
    "id": "97gYTdw3xt17"
   },
   "source": [
    "## Prepare the Audio Embedding Model\n",
    "\n",
    "_Note: if you are on a Colab, make sure your \"Runtime type\" has \"Hardware Acceleration\" set to GPU for best performance. The cell below will try to auto-detect and adapt to your setup, please adapt to your specific hardware setup if necessary._\n",
    "\n",
    "_Note: please keep in mind that the cell below may take a few minutes to load the full model, unless already cached locally._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X26ePde5yLaZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X26ePde5yLaZ",
    "outputId": "3118872a-141f-485e-c694-1d911de8cd28"
   },
   "outputs": [],
   "source": [
    "GPU_AVAILABLE = torch.cuda.device_count() > 0\n",
    "\n",
    "if GPU_AVAILABLE:\n",
    "    # load the default model on the GPU\n",
    "    model = AudioTagging(checkpoint_path=None, device=\"cuda\")\n",
    "    print(\"\\nLoaded the sound embedding model on the GPU.\")\n",
    "else:\n",
    "    # fall back to the CPU\n",
    "    model = AudioTagging(checkpoint_path=None, device=\"cpu\")\n",
    "    print(\n",
    "        \"\\nLoaded the sound embedding model on the CPU. Reduced defaults \"\n",
    "        \"will be used. Please consider upgrading to a GPU-powered \"\n",
    "        \"hardware for best experience.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0670b30f-927f-47da-b71d-0a99092c3f58",
   "metadata": {
    "id": "0670b30f-927f-47da-b71d-0a99092c3f58"
   },
   "source": [
    "## Create a DB table through CassIO\n",
    "\n",
    "When an instance of `VectorTable` is created, CassIO takes care of the underlying database operations. An important parameter to supply is the embedding vector dimension (fixed by the choice of the PANNs model being used):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ENEwxldS_Vqy",
   "metadata": {
    "id": "ENEwxldS_Vqy"
   },
   "outputs": [],
   "source": [
    "table_name = 'audio_table'\n",
    "embedding_dimension = 2048\n",
    "\n",
    "v_table = VectorTable(\n",
    "    session=session,\n",
    "    keyspace=keyspace,\n",
    "    table=table_name,\n",
    "    embedding_dimension=embedding_dimension,\n",
    "    primary_key_type='TEXT',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fe256f-9efb-41f0-8803-d99696c6089b",
   "metadata": {
    "id": "c1fe256f-9efb-41f0-8803-d99696c6089b"
   },
   "source": [
    "# Compute and store embedding vectors for audio\n",
    "\n",
    "This cell processes the audio samples you just loaded. By working in batches, the embedding vectors are evaluated through the PANNs model, and the result is stored in the Cassandra / Astra DB table by invoking the `put` method of `VectorTable`.\n",
    "\n",
    "_Note: this operation will take some minutes. Feel free to adjust the total amount of sound clips to process from the library for a quicker demo._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pMUTakZmG2Ye",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "364f301a0d6e45f88941f6fca8f2fc08",
      "0592aee1a707469cab62a547964cd4d9",
      "7358ce454e124aa9a4a9ca2f895ab113",
      "092483b7af7e43869bee0bb71176d644",
      "dae2f4db836343a88a4ab6140472e8eb",
      "7b318ae78b4c4e11a01e7ada1a30111d",
      "5e9083ead6564bd7a2779d8ba6a5dcc6",
      "8bfff206d9b349369fc6dc03b29d6755",
      "d34fcf3c2c5f4a95836b095e8b1f7ccf",
      "a0077b54f2ca47488c8890f883ab4f08",
      "f53c4d8006574633972748d6465ed12d"
     ]
    },
    "id": "pMUTakZmG2Ye",
    "outputId": "41400474-6c7a-4e56-f815-8f2e9e04487d"
   },
   "outputs": [],
   "source": [
    "if GPU_AVAILABLE:\n",
    "    BATCH_SIZE = 100\n",
    "    SAMPLES_TO_PROCESS = 2000\n",
    "else:\n",
    "    BATCH_SIZE = 20\n",
    "    SAMPLES_TO_PROCESS = 500\n",
    "\n",
    "\n",
    "for i in tqdm(range(0, SAMPLES_TO_PROCESS, BATCH_SIZE)):\n",
    "    # Find end of batch\n",
    "    i_end = min(i + BATCH_SIZE, SAMPLES_TO_PROCESS)\n",
    "    # Extract batch filename and audio signal.\n",
    "    # (the filename will also serve as row primary key on DB)\n",
    "    batch_filenames = audio_dataset['filename'][i:i_end]\n",
    "    batch_audio = audios[i:i_end]\n",
    "    # Generate embeddings for all the audios in the batch\n",
    "    _, batch_embeddings_np = model.inference(batch_audio)\n",
    "    batch_categories = audio_dataset[\"category\"][i:i_end]\n",
    "    # Insert all entries in the batch concurrently\n",
    "    futures = []\n",
    "    for filename, category, embedding_np in zip(\n",
    "        batch_filenames, batch_categories, batch_embeddings_np\n",
    "    ):\n",
    "        metadata = {\n",
    "            'category': category,\n",
    "            'filename': filename,\n",
    "        }\n",
    "        # From a Numpy array to a plain list of floats:\n",
    "        embedding = embedding_np.tolist()\n",
    "        futures.append(v_table.put_async(\n",
    "            document=filename,\n",
    "            embedding_vector=embedding,\n",
    "            document_id=filename,\n",
    "            metadata=metadata,\n",
    "            ttl_seconds=None,\n",
    "        ))\n",
    "    for future in futures:\n",
    "        future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa5b74",
   "metadata": {},
   "source": [
    "Note that, as customary in Cassandra with (potentially) large binary blobs, you did not store the raw audio signal in the table itself. Rather, in the `document` field of the `VectorTable`, you have stored the necessary metadata to retrieve the audio file itself in some other way (which on a realistic setup could be a S3 bucket or similar). In this case this amounts to the `filename` field.\n",
    "\n",
    "To emulate a more realistic setup, create a dictionary for later lookup by filename:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81899e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios_by_filename = {\n",
    "    dataset_row[\"filename\"]: dataset_row[\"audio\"][\"array\"]\n",
    "    for dataset_row in audio_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45925b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an example:\n",
    "print(str(list(audios_by_filename[\"1-100038-A-14.wav\"]))[:64] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JiainTLa1U1q",
   "metadata": {
    "id": "JiainTLa1U1q"
   },
   "source": [
    "## Run a similarity search\n",
    "\n",
    "You will now obtain a new audio file and search for samples similar to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407bfce",
   "metadata": {},
   "source": [
    "Get the sound of a cat meowing with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ge8HGNwJ0bDB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ge8HGNwJ0bDB",
    "outputId": "651ad1e7-9a81-4344-f37d-f403a64bdc12"
   },
   "outputs": [],
   "source": [
    "!wget https://storage.googleapis.com/audioset/miaow_16k.wav"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zhrz9EtLmnQv",
   "metadata": {
    "id": "zhrz9EtLmnQv"
   },
   "source": [
    "Load the audio using the `librosa` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UlkXCOgm01rC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "UlkXCOgm01rC",
    "outputId": "3ed4bd66-1602-4ec3-d2f2-5870c406c391"
   },
   "outputs": [],
   "source": [
    "meow_sound, _ = librosa.load(\"miaow_16k.wav\", sr=22100)\n",
    "print(\"Meow!\")\n",
    "display(Audio(meow_sound, rate=22100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8yUPkZ1DuSHX",
   "metadata": {
    "id": "8yUPkZ1DuSHX"
   },
   "source": [
    "In order to run the search, first get the embedding vector for the input file, then use it to run a similarity search on the CassIO `VectorTable`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xwf3xsh40523",
   "metadata": {
    "id": "xwf3xsh40523"
   },
   "outputs": [],
   "source": [
    "# Reshape query audio\n",
    "reshaped_meow = meow_sound[None, :]\n",
    "# Get the embeddings for the new audio\n",
    "_, query_embedding_np = model.inference(reshaped_meow)\n",
    "query_embedding = query_embedding_np.tolist()[0]\n",
    "\n",
    "matches = v_table.search(\n",
    "    embedding_vector=query_embedding,\n",
    "    top_k=5,\n",
    "    metric='cos',\n",
    "    metric_threshold=None,\n",
    ")\n",
    "\n",
    "# Show a \"play\" widget for the top results\n",
    "for match_i, match in enumerate(matches):\n",
    "    print(f\"Match {match_i}: {match['document']} \", end='')\n",
    "    print(f\"(category: {match['metadata']['category']}, \", end='')\n",
    "    print(f\"distance: {match['distance']:.4f})\")\n",
    "    # retrieve the audio clip content from \"storage\"\n",
    "    match_audio = audios_by_filename[match[\"document\"]]\n",
    "    display(Audio(match_audio, rate=44100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3-5Y0en3tPb0",
   "metadata": {
    "id": "3-5Y0en3tPb0"
   },
   "source": [
    "## Experiment with your own WAV file\n",
    "\n",
    "In this section, you can supply any WAV audio file of your own to have a bit of fun.\n",
    "\n",
    "While you're at it, do a bit of refactoring of the audio processing steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed14d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wav_filepath_to_audio(filepath, bitrate=22100):\n",
    "    loaded_audio, _ = librosa.load(filepath, sr=bitrate)\n",
    "    return loaded_audio\n",
    "\n",
    "    \n",
    "def audio_similarity_search(query_audio, top_k=5):\n",
    "    query_audio1 = query_audio[None, :]\n",
    "    # get the embeddings for the audio from the model\n",
    "    _, query_embedding_np = model.inference(query_audio1)\n",
    "    query_embedding = query_embedding_np.tolist()[0]\n",
    "    matches = v_table.search(\n",
    "        embedding_vector=query_embedding,\n",
    "        top_k=top_k,\n",
    "        metric='cos',\n",
    "        metric_threshold=None,\n",
    "    )\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19afe047",
   "metadata": {},
   "source": [
    "Now try providing a sound file of yours (skip this part if you want):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cYnpzEN3tVlh",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "cYnpzEN3tVlh",
    "outputId": "0a1c8740-c274-4cd1-f027-4eb00b7b6265"
   },
   "outputs": [],
   "source": [
    "if IS_COLAB:\n",
    "    print(\"Please upload a WAV file from your computer:\")\n",
    "    uploaded = files.upload()\n",
    "    wav_file_title = list(uploaded.keys())[0]\n",
    "    wav_filepath = os.path.join(os.getcwd(), wav_file_title)\n",
    "else:\n",
    "    wav_filepath = input(\"Please provide the full path to a WAV file: \")\n",
    "\n",
    "supplied_audio = wav_filepath_to_audio(wav_filepath)\n",
    "print(\"Your query sound:\")\n",
    "display(Audio(supplied_audio, rate=22100))\n",
    "\n",
    "print(\"Similar clips:\")\n",
    "for match in audio_similarity_search(supplied_audio, top_k=3):\n",
    "    print(f\"{match['document_id']} ({match['metadata']['category']})\")\n",
    "    match_audio = audios_by_filename[match[\"document\"]]\n",
    "    display(Audio(match_audio, rate=44100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yXwEwwWmcs8E",
   "metadata": {
    "id": "yXwEwwWmcs8E"
   },
   "source": [
    "## Sound Similarity Web App\n",
    "\n",
    "The following cells set up and launch a simple application, powered by [Gradio](https://www.gradio.app/) demonstrating the sound similarity search seen so far.\n",
    "\n",
    "In its essence, Gradio makes it easy to expose a graphical interface around the following function, built using the components seen earlier, that accepts a user-provided sound as input and returns a number of results from the library, found by similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1OuZwiugvHWv",
   "metadata": {
    "id": "1OuZwiugvHWv"
   },
   "outputs": [],
   "source": [
    "# output_file = 'output_audio.wav'\n",
    "# NUM_RESULT_WIDGETS = 5\n",
    "\n",
    "# def gradio_upload_audio(input_file):\n",
    "#     if input_file:\n",
    "#         input_audio = wav_filepath_to_audio(input_file)\n",
    "#         found_audios = []\n",
    "#         for match in audio_similarity_search(input_audio, top_k=NUM_RESULT_WIDGETS):\n",
    "#             match_audio = audios_by_filename[match[\"document\"]]\n",
    "#             sample_rate = 44100\n",
    "#             wavfile.write(output_file , sample_rate , match_audio)\n",
    "#             found_audios.append(output_file)\n",
    "#     else:\n",
    "#         found_audios = []\n",
    "#     # pad the result in any case to the number of displayed widgets\n",
    "#     return found_audios + [None]*(NUM_RESULT_WIDGETS-len(found_audios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a2df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TUPLY FORMAT\n",
    "NUM_RESULT_WIDGETS = 5\n",
    "\n",
    "def gradio_upload_audio(input_sound):\n",
    "    if input_sound:\n",
    "        # Warning: Gradio sound signals arrive as 'int' between +/- 32767.\n",
    "        # First these must be normalized to [-1:+1]\n",
    "        # (see https://github.com/gradio-app/gradio/issues/2789)\n",
    "        max_sound_signal = np.abs(input_sound[1]).max()\n",
    "        input_sound_norm_signal = input_sound[1]/max_sound_signal\n",
    "        input_audio = np.array(input_sound_norm_signal, dtype=np.float32)\n",
    "        found_audios = []\n",
    "        for match in audio_similarity_search(input_audio, top_k=NUM_RESULT_WIDGETS):\n",
    "            match_audio = audios_by_filename[match[\"document\"]]\n",
    "            sample_rate = 44100\n",
    "            # normalize back to the Gradio y-scale for sounds:\n",
    "            this_result = (sample_rate, match_audio * 32767)\n",
    "            found_audios.append(this_result)\n",
    "    else:\n",
    "        found_audios = []\n",
    "    # pad the result in any case to the number of displayed widgets\n",
    "    return found_audios + [None]*(NUM_RESULT_WIDGETS-len(found_audios))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qmwv1HnlAt3x",
   "metadata": {
    "id": "qmwv1HnlAt3x"
   },
   "source": [
    "The next cell starts the Gradio app. Please keep in mind that:\n",
    "\n",
    "- The cell will keep running as long as the UI is running. **Interrupt the notebook kernel to regain control** (e.g. to modify and re-launch, or execute other cells, etc).\n",
    "- The cell output will give both a local URL to access the application, and an URL such as `https://<....>.gradio.live` to reach it from anywhere. **Use the latter link from Colab and when sharing with others**. _(The link will expire after a certain time.)_\n",
    "- The UI will also be shown within the notebook below the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ywAXKUd6NgLF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 987
    },
    "id": "ywAXKUd6NgLF",
    "outputId": "25f1a44e-ada1-47ad-fe9d-25c5b216dd0e"
   },
   "outputs": [],
   "source": [
    "# sound_ui = gradio.Interface(\n",
    "#     fn=gradio_upload_audio,\n",
    "#     inputs=gradio.inputs.Audio(type=\"filepath\", label=\"Your query audio\"),\n",
    "#     outputs=[\n",
    "#         gradio.outputs.Audio(type=\"filepath\", label=f\"Search result #{output_i}\")\n",
    "#         for output_i in range(NUM_RESULT_WIDGETS)\n",
    "#     ],\n",
    "#     title=\"Sound Similarity Search with CassIO & Vector Database\",\n",
    "# )\n",
    "\n",
    "# sound_ui.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47be7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sound_ui = gradio.Interface(\n",
    "    fn=gradio_upload_audio,\n",
    "    inputs=gradio.inputs.Audio(type=\"numpy\", label=\"Your query audio\"),\n",
    "    outputs=[\n",
    "        gradio.outputs.Audio(type=\"numpy\", label=f\"Search result #{output_i}\")\n",
    "        for output_i in range(NUM_RESULT_WIDGETS)\n",
    "    ],\n",
    "    title=\"Sound Similarity Search with CassIO & Vector Database\",\n",
    ")\n",
    "\n",
    "sound_ui.launch(share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
