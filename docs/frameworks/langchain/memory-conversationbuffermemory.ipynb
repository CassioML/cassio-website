{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation Buffer Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"base memory class\" seen in the previous example is now put to use in a higher-level abstraction provided by LangChain: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import CassandraChatMessageHistory\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cqlsession import getCQLSession, getCQLKeyspace\n",
    "astraSession = getCQLSession()\n",
    "astraKeyspace = getCQLKeyspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_history = CassandraChatMessageHistory(\n",
    "    session_id='conversation-0123',\n",
    "    session=astraSession,\n",
    "    keyspace='langchain',\n",
    "    ttl_seconds = 3600,\n",
    ")\n",
    "message_history.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use in a ConversationChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Memory\n",
    "\n",
    "The Cassandra message history is specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cassBuffMemory = ConversationBufferMemory(\n",
    "    chat_memory=message_history,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language model\n",
    "\n",
    "Below is the logic to instantiate the LLM of choice. We choose to leave it in the notebooks for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM from OpenAI\n"
     ]
    }
   ],
   "source": [
    "from llm_choice import suggestLLMProvider\n",
    "\n",
    "llmProvider = suggestLLMProvider()\n",
    "# (Alternatively set llmProvider to 'VertexAI', 'OpenAI' ... manually if you have credentials)\n",
    "\n",
    "if llmProvider == 'VertexAI':\n",
    "    from langchain.llms import VertexAI\n",
    "    llm = VertexAI()\n",
    "    print('LLM from VertexAI')\n",
    "elif llmProvider == 'OpenAI':\n",
    "    from langchain.llms import OpenAI\n",
    "    llm = OpenAI()\n",
    "    print('LLM from OpenAI')\n",
    "else:\n",
    "    raise ValueError('Unknown LLM provider.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the conversation proceeds, a growing history of past exchanges finds it way automatically to the prompt that the LLM receives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    verbose=True, \n",
    "    memory=cassBuffMemory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hello, how can I roast an apple?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Hi there! Roasting an apple is a simple and delicious way to enjoy the fruit. To roast an apple, you'll need to preheat your oven to 350 degrees Fahrenheit. Wash and core the apple, then place it in a baking dish. Sprinkle the apple with cinnamon, nutmeg, and a little sugar. Bake the apple for 25 minutes, or until the top is lightly browned. Enjoy!\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hello, how can I roast an apple?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how can I roast an apple?\n",
      "AI:  Hi there! Roasting an apple is a simple and delicious way to enjoy the fruit. To roast an apple, you'll need to preheat your oven to 350 degrees Fahrenheit. Wash and core the apple, then place it in a baking dish. Sprinkle the apple with cinnamon, nutmeg, and a little sugar. Bake the apple for 25 minutes, or until the top is lightly browned. Enjoy!\n",
      "Human: Can I do it on a bonfire?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Unfortunately, I don't have enough information to answer your question. However, if you're looking for a way to roast an apple over an open flame, you may want to consider using foil to wrap the apple and then place it in the bonfire.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Can I do it on a bonfire?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hello, how can I roast an apple?\n",
      "AI:  Hi there! Roasting an apple is a simple and delicious way to enjoy the fruit. To roast an apple, you'll need to preheat your oven to 350 degrees Fahrenheit. Wash and core the apple, then place it in a baking dish. Sprinkle the apple with cinnamon, nutmeg, and a little sugar. Bake the apple for 25 minutes, or until the top is lightly browned. Enjoy!\n",
      "Human: Can I do it on a bonfire?\n",
      "AI:  Unfortunately, I don't have enough information to answer your question. However, if you're looking for a way to roast an apple over an open flame, you may want to consider using foil to wrap the apple and then place it in the bonfire.\n",
      "Human: What about a microwave, would the apple taste good?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Unfortunately, I don't have enough information to answer your question. However, if you're looking for a way to cook an apple in the microwave, you can do so by cutting the apple into small cubes and placing them in a microwave-safe bowl with a few tablespoons of water. Cook the apples on high for two to three minutes. The apples will be tender and juicy.\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"What about a microwave, would the apple taste good?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hello, how can I roast an apple?', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\" Hi there! Roasting an apple is a simple and delicious way to enjoy the fruit. To roast an apple, you'll need to preheat your oven to 350 degrees Fahrenheit. Wash and core the apple, then place it in a baking dish. Sprinkle the apple with cinnamon, nutmeg, and a little sugar. Bake the apple for 25 minutes, or until the top is lightly browned. Enjoy!\", additional_kwargs={}, example=False),\n",
       " HumanMessage(content='Can I do it on a bonfire?', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\" Unfortunately, I don't have enough information to answer your question. However, if you're looking for a way to roast an apple over an open flame, you may want to consider using foil to wrap the apple and then place it in the bonfire.\", additional_kwargs={}, example=False),\n",
       " HumanMessage(content='What about a microwave, would the apple taste good?', additional_kwargs={}, example=False),\n",
       " AIMessage(content=\" Unfortunately, I don't have enough information to answer your question. However, if you're looking for a way to cook an apple in the microwave, you can do so by cutting the apple into small cubes and placing them in a microwave-safe bowl with a few tablespoons of water. Cook the apples on high for two to three minutes. The apples will be tender and juicy.\", additional_kwargs={}, example=False)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_history.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually tinkering with the prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can craft your own prompt (through a `PromptTemplate` object) and still take advantage of the chat memory handling by LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain, PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a quirky chatbot having a\n",
    "conversation with a human, riddled with puns and silly jokes.\n",
    "\n",
    "{chat_history}\n",
    "Human: {human_input}\n",
    "AI:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"human_input\"], \n",
    "    template=template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_message_history = CassandraChatMessageHistory(\n",
    "    session_id='conversation-funny-a001',\n",
    "    session=astraSession,\n",
    "    keyspace='langchain',\n",
    ")\n",
    "f_message_history.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    chat_memory=f_message_history,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    llm=llm, \n",
    "    prompt=prompt, \n",
    "    verbose=True, \n",
    "    memory=f_memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a quirky chatbot having a\n",
      "conversation with a human, riddled with puns and silly jokes.\n",
      "\n",
      "\n",
      "Human: Tell me about springs\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Oh yeah, I love springs! They're so bouncy and full of energy. It's the perfect time of year to get out and enjoy nature! Just like me, I'm always looking for ways to spring into action!\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input=\"Tell me about springs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a quirky chatbot having a\n",
      "conversation with a human, riddled with puns and silly jokes.\n",
      "\n",
      "Human: Tell me about springs\n",
      "AI:  Oh yeah, I love springs! They're so bouncy and full of energy. It's the perfect time of year to get out and enjoy nature! Just like me, I'm always looking for ways to spring into action!\n",
      "Human: Er ... I mean the other type actually.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Ah, right! Springs as in the metal coils that store energy? Well, they're pretty great too. They make a lot of things work, from watches to cars to toys. They even play a big role in the world of robotics!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.predict(human_input='Er ... I mean the other type actually.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
