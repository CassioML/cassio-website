{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84094469",
   "metadata": {},
   "source": [
    "# Caching LLM responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ddaf62",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use Cassandra for a basic prompt/response cache.\n",
    "\n",
    "Such a cache prevents running an LLM invocation more than once for the very same prompt, thus saving on latency and token usage. The cache retrieval logic is based on an exact match, as will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec81edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import CassandraCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9e24fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cqlsession import getCQLSession, getCQLKeyspace\n",
    "cqlMode = 'astra_db' # 'astra_db'/'local'\n",
    "session = getCQLSession(mode=cqlMode)\n",
    "keyspace = getCQLKeyspace(mode=cqlMode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65bff51",
   "metadata": {},
   "source": [
    "Create a `CassandraCache` and configure it globally for LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445307fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.llm_cache = CassandraCache(\n",
    "    session=session,\n",
    "    keyspace=keyspace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34b7e97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b619bb",
   "metadata": {},
   "source": [
    "Below is the logic to instantiate the LLM of choice. We chose to leave it in the notebooks for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a533119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM from OpenAI\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llm_choice import suggestLLMProvider\n",
    "\n",
    "llmProvider = suggestLLMProvider()\n",
    "# (Alternatively set llmProvider to 'GCP_VertexAI', 'OpenAI', 'Azure_OpenAI' ... manually if you have credentials)\n",
    "\n",
    "if llmProvider == 'GCP_VertexAI':\n",
    "    from langchain.llms import VertexAI\n",
    "    llm = VertexAI()\n",
    "    print('LLM from Vertex AI')\n",
    "elif llmProvider == 'OpenAI':\n",
    "    os.environ['OPENAI_API_TYPE'] = 'open_ai'\n",
    "    from langchain.llms import OpenAI\n",
    "    llm = OpenAI()\n",
    "    print('LLM from OpenAI')\n",
    "elif llmProvider == 'Azure_OpenAI':\n",
    "    os.environ['OPENAI_API_TYPE'] = 'azure'\n",
    "    os.environ['OPENAI_API_VERSION'] = os.environ['AZURE_OPENAI_API_VERSION']\n",
    "    os.environ['OPENAI_API_BASE'] = os.environ['AZURE_OPENAI_API_BASE']\n",
    "    os.environ['OPENAI_API_KEY'] = os.environ['AZURE_OPENAI_API_KEY']\n",
    "    from langchain.llms import AzureOpenAI\n",
    "    llm = AzureOpenAI(temperature=0, model_name=os.environ['AZURE_OPENAI_LLM_MODEL'],\n",
    "                      engine=os.environ['AZURE_OPENAI_LLM_DEPLOYMENT'])\n",
    "    print('LLM from Azure OpenAI')\n",
    "else:\n",
    "    raise ValueError('Unknown LLM provider.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f17cce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 1.67 ms, total: 130 ms\n",
      "Wall time: 2.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nSpiders usually have eight eyes, but some spiders can have as many as twelve eyes.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "SPIDER_QUESTION_FORM_1 = \"How many eyes do spiders have?\"\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm(SPIDER_QUESTION_FORM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47bc4bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.77 ms, sys: 2.85 ms, total: 5.63 ms\n",
      "Wall time: 182 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nSpiders usually have eight eyes, but some spiders can have as many as twelve eyes.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# This time we expect a much shorter answer time\n",
    "llm(SPIDER_QUESTION_FORM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88d657dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.8 ms, sys: 5.08 ms, total: 29.9 ms\n",
      "Wall time: 1.34 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nSpiders typically have eight eyes, although some species may have fewer or more.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "SPIDER_QUESTION_FORM_2 = \"How many eyes do spiders generally have?\"\n",
    "# This will again take 1-2 seconds, being a different string\n",
    "llm(SPIDER_QUESTION_FORM_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5048a336",
   "metadata": {},
   "source": [
    "### Stale entry control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ca8cd5",
   "metadata": {},
   "source": [
    "#### Time-To-Live (TTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de2adf",
   "metadata": {},
   "source": [
    "You can configure a time-to-live property of the cache, with the effect of automatic eviction of cached entries after a certain time.\n",
    "\n",
    "Setting `langchain.llm_cache` to the following will have the effect that entries vanish in an hour (also supplying a custom table name is demonstrated):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faec79f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheWithTTL = CassandraCache(\n",
    "    session=session,\n",
    "    keyspace=keyspace,\n",
    "    table_name=\"langchain_llm_cache\",\n",
    "    ttl_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8ec77",
   "metadata": {},
   "source": [
    "#### Manual cache eviction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b414d43",
   "metadata": {},
   "source": [
    "Alternatively, you can invalidate cached entries one at a time - for that, you'll need to provide the very LLM this entry is associated to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56df34d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.99 ms, sys: 0 ns, total: 7.99 ms\n",
      "Wall time: 150 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nSpiders typically have eight eyes, although some species may have fewer or more.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm(SPIDER_QUESTION_FORM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d42dcb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache.delete_through_llm(SPIDER_QUESTION_FORM_2, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed25580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 ms, sys: 3.52 ms, total: 17.4 ms\n",
      "Wall time: 1.02 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nMost spiders have eight eyes, although some species have fewer.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm(SPIDER_QUESTION_FORM_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3193c67",
   "metadata": {},
   "source": [
    "#### Whole-cache deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8d74e6",
   "metadata": {},
   "source": [
    "As you might have seen at the beginning of this notebook, you can also clear the cache entirely: **all** stored entries, for all models, will be evicted at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff899ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
