{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab953acd",
   "metadata": {},
   "source": [
    "# Caching LLM responses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ed9c73",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use Cassandra for a basic prompt/response cache.\n",
    "\n",
    "Such a cache prevents running an LLM invocation more than once for the very same prompt, thus saving on latency and token usage. The cache retrieval logic is based on an exact match, as will be shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8e8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import CassandraCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdfd4644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.virtualenvs/langchain-cassio-3.10/lib/python3.10/site-packages/cassandra/datastax/cloud/__init__.py:173: DeprecationWarning: ssl.PROTOCOL_TLS is deprecated\n",
      "  ssl_context = SSLContext(PROTOCOL_TLS)\n",
      "/home/stefano/.virtualenvs/langchain-cassio-3.10/lib/python3.10/site-packages/cassandra/io/asyncorereactor.py:347: DeprecationWarning: ssl.match_hostname() is deprecated\n",
      "  self._connect_socket()\n"
     ]
    }
   ],
   "source": [
    "from cqlsession import getCQLSession, getCQLKeyspace\n",
    "astraSession = getCQLSession()\n",
    "astraKeyspace = getCQLKeyspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c559dc2",
   "metadata": {},
   "source": [
    "Create a `CassandraCache` and configure it globally for LangChain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a9aea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.llm_cache = CassandraCache(\n",
    "    session=astraSession,\n",
    "    keyspace=astraKeyspace,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f45901",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c16f0",
   "metadata": {},
   "source": [
    "Below is the logic to instantiate the LLM of choice. We choose to leave it in the notebooks for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1460b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stefano/.virtualenvs/langchain-cassio-3.10/lib/python3.10/site-packages/google/api_core/operations_v1/abstract_operations_client.py:17: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
      "  from distutils import util\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM from VertexAI\n"
     ]
    }
   ],
   "source": [
    "from llm_choice import suggestLLMProvider\n",
    "\n",
    "llmProvider = suggestLLMProvider()\n",
    "# (Alternatively set llmProvider to 'VertexAI', 'OpenAI' ... manually if you have credentials)\n",
    "\n",
    "if llmProvider == 'VertexAI':\n",
    "    from langchain.llms import VertexAI\n",
    "    llm = VertexAI()\n",
    "    print('LLM from VertexAI')\n",
    "elif llmProvider == 'OpenAI':\n",
    "    from langchain.llms import OpenAI\n",
    "    llm = OpenAI()\n",
    "    print('LLM from OpenAI')\n",
    "else:\n",
    "    raise ValueError('Unknown LLM provider.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80a40683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 ms, sys: 1.22 ms, total: 21.1 ms\n",
      "Wall time: 1.43 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spiders have eight eyes.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "SPIDER_QUESTION_FORM_1 = \"How many eyes do spiders have?\"\n",
    "# The first time, it is not yet in cache, so it should take longer\n",
    "llm(SPIDER_QUESTION_FORM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea8c691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.83 ms, sys: 263 µs, total: 5.1 ms\n",
      "Wall time: 124 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spiders have eight eyes.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# This time we expect a much shorter answer time\n",
    "llm(SPIDER_QUESTION_FORM_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8f90ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 ms, sys: 3.34 ms, total: 9.26 ms\n",
      "Wall time: 852 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spiders generally have eight eyes.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "SPIDER_QUESTION_FORM_2 = \"How many eyes do spiders generally have?\"\n",
    "# This will again take 1-2 seconds, being a different string\n",
    "llm(SPIDER_QUESTION_FORM_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbee0ec",
   "metadata": {},
   "source": [
    "### Stale entry control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2decada",
   "metadata": {},
   "source": [
    "#### Time-To-Live (TTL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e3dc92",
   "metadata": {},
   "source": [
    "You can configure a time-to-live property of the cache, with the effect of automatic eviction of cached entries after a certain time.\n",
    "\n",
    "Setting `langchain.llm_cache` to the following will have the effect that entries vanish in an hour:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96022986",
   "metadata": {},
   "outputs": [],
   "source": [
    "cacheWithTTL = CassandraCache(\n",
    "    session=astraSession,\n",
    "    keyspace=astraKeyspace,\n",
    "    ttl_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e1642d",
   "metadata": {},
   "source": [
    "#### Manual cache eviction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4563fed3",
   "metadata": {},
   "source": [
    "Alternatively, you can invalidate cached entries one at a time - for that, you'll need to provide the very LLM this entry is associated to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4767f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.36 ms, sys: 105 µs, total: 4.47 ms\n",
      "Wall time: 120 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spiders generally have eight eyes.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm(SPIDER_QUESTION_FORM_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4fca002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache.delete_through_llm(SPIDER_QUESTION_FORM_2, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b0391e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 621 µs, total: 10.7 ms\n",
      "Wall time: 964 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spiders generally have eight eyes.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "llm(SPIDER_QUESTION_FORM_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767487c3",
   "metadata": {},
   "source": [
    "#### Whole-cache deletion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5724b2de",
   "metadata": {},
   "source": [
    "As you might have seen at the beginning of this notebook, you can also clear the cache entirely: **all** stored entries, for all models, will be evicted at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a02ca7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langchain.llm_cache.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
