{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057478c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import createCassandraPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9d67e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cqlsession import getCQLSession, getCQLKeyspace\n",
    "astraSession = getCQLSession()\n",
    "astraKeyspace = getCQLKeyspace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f88708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the prompt for a single message in the chat sequence.\n",
    "# We create with the cassandra-powered data-extraction logic.\n",
    "systemTemplate = \"\"\"\n",
    "You are a chat assistant, helping a user of age {user_age} from a city\n",
    "they refer to as {city_nickname}.\n",
    "\"\"\"\n",
    "\n",
    "cassSystemPrompt = createCassandraPromptTemplate(\n",
    "    session=astraSession,\n",
    "    keyspace=astraKeyspace,\n",
    "    template=systemTemplate,\n",
    "    # this will work because input_variables are the actual variables passed in formatting:\n",
    "    input_variables=['city', 'name'],\n",
    "    field_mapper={\n",
    "        'user_age': ('people', 'age'),\n",
    "        'city_nickname': ('nickname_by_city', 'nickname'),\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d824c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "systemMessagePrompt = SystemMessagePromptTemplate(prompt=cassSystemPrompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe94f03",
   "metadata": {},
   "source": [
    "## Putting this (DB-connected) system message into a broader chat sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343acb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "humanTemplate = \"{text}\"\n",
    "humanMessagePrompt = HumanMessagePromptTemplate.from_template(humanTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b9a492",
   "metadata": {},
   "outputs": [],
   "source": [
    "cassChatPrompt = ChatPromptTemplate.from_messages([systemMessagePrompt, humanMessagePrompt])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5dd629",
   "metadata": {},
   "source": [
    "### Trying an all-encompassing rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5677b9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cassChatPrompt.format_prompt(\n",
    "    city='turin',\n",
    "    name='beppe',\n",
    "    text='Assistant, please help me!'\n",
    ").to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bba52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Partialing is not implemented for ChatPromptTemplate (this is at the LangChain layer)\n",
    "try:\n",
    "    cassChatPartialPrompt = cassChatPrompt.partial(city='turin', name='beppe')\n",
    "except NotImplementedError:\n",
    "    print('\"NotImplementedError\" raised by partialing ChatPromptTemplate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
